"""
æ•°æ®æºæœåŠ¡ä¸»åº”ç”¨
FastAPIåº”ç”¨å…¥å£ï¼Œé›†æˆæ‰€æœ‰APIè·¯ç”±å’Œä¸­é—´ä»¶
"""

import asyncio
import sys
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
from fastapi.openapi.docs import get_swagger_ui_html, get_redoc_html
from fastapi.openapi.utils import get_openapi
import uvicorn
from loguru import logger
import signal
from datetime import datetime

# å¯¼å…¥é…ç½®å’Œä¾èµ–
from .config.settings import get_settings
from .database.database import init_database, close_database, get_database_manager
from .crawler.crawler_manager import get_crawler_manager
from .proxy.proxy_manager import get_proxy_manager

# å¯¼å…¥APIè·¯ç”±
from .api.crawler import router as crawler_router
from .api.content import router as content_router
from .api.proxy import router as proxy_router

# è·å–é…ç½®
settings = get_settings()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    logger.info("ğŸš€ æ•°æ®æºæœåŠ¡å¯åŠ¨ä¸­...")
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        logger.info("ğŸ“Š åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        await init_database()
        
        # åˆå§‹åŒ–çˆ¬è™«ç®¡ç†å™¨
        logger.info("ğŸ•·ï¸ åˆå§‹åŒ–çˆ¬è™«ç®¡ç†å™¨...")
        crawler_manager = await get_crawler_manager()
        await crawler_manager.initialize()
        
        # åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨
        logger.info("ğŸŒ åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨...")
        proxy_manager = await get_proxy_manager()
        await proxy_manager.initialize()
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        def signal_handler(signum, frame):
            logger.info(f"æ”¶åˆ°é€€å‡ºä¿¡å· {signum}")
            asyncio.create_task(graceful_shutdown())
        
        if sys.platform != 'win32':
            signal.signal(signal.SIGTERM, signal_handler)
            signal.signal(signal.SIGINT, signal_handler)
        
        logger.success("âœ… æ•°æ®æºæœåŠ¡å¯åŠ¨å®Œæˆ")
        
        yield
        
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        raise
    
    finally:
        # å…³é—­æ—¶æ‰§è¡Œ
        logger.info("ğŸ›‘ æ•°æ®æºæœåŠ¡å…³é—­ä¸­...")
        await graceful_shutdown()


async def graceful_shutdown():
    """ä¼˜é›…å…³é—­"""
    try:
        # åœæ­¢çˆ¬è™«ç®¡ç†å™¨
        logger.info("åœæ­¢çˆ¬è™«ç®¡ç†å™¨...")
        crawler_manager = await get_crawler_manager()
        await crawler_manager.cleanup()
        
        # å…³é—­æ•°æ®åº“è¿æ¥
        logger.info("å…³é—­æ•°æ®åº“è¿æ¥...")
        await close_database()
        
        logger.success("âœ… æœåŠ¡å·²ä¼˜é›…å…³é—­")
        
    except Exception as e:
        logger.error(f"âŒ å…³é—­æœåŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="å†å²æ–‡æœ¬é¡¹ç›® - æ•°æ®æºæœåŠ¡",
    description="""
    ## æ•°æ®æºæœåŠ¡ API
    
    æä¾›å¤šå¹³å°å†…å®¹çˆ¬å–ã€ä»£ç†ç®¡ç†å’Œå†…å®¹å¤„ç†åŠŸèƒ½çš„å¾®æœåŠ¡ã€‚
    
    ### ä¸»è¦åŠŸèƒ½
    - ğŸ•·ï¸ **çˆ¬è™«ç®¡ç†**: æ”¯æŒä»Šæ—¥å¤´æ¡ã€ç™¾å®¶å·ã€å°çº¢ä¹¦ç­‰å¹³å°
    - ğŸ“„ **å†…å®¹ç®¡ç†**: æ‰‹åŠ¨æ·»åŠ ã€æ‰¹é‡å¯¼å…¥ã€æŸ¥è¯¢å’Œæ›´æ–°å†…å®¹
    - ğŸŒ **ä»£ç†ç®¡ç†**: ä»£ç†æ± ç®¡ç†ã€è‡ªåŠ¨æµ‹è¯•å’Œè½®æ¢
    - ğŸ“Š **ç›‘æ§ç»Ÿè®¡**: å®æ—¶çŠ¶æ€ç›‘æ§å’Œæ•°æ®ç»Ÿè®¡
    
    ### æŠ€æœ¯æ ˆ
    - **æ¡†æ¶**: FastAPI + Python 3.9+
    - **æ•°æ®åº“**: MongoDB + Redis
    - **çˆ¬è™«**: Scrapy + Selenium
    - **ä»£ç†**: å¤šä¾›åº”å•†ä»£ç†æ± 
    
    ### ä½¿ç”¨è¯´æ˜
    1. ä½¿ç”¨ `/crawlers/` æ¥å£ç®¡ç†çˆ¬è™«ä»»åŠ¡
    2. ä½¿ç”¨ `/content/` æ¥å£ç®¡ç†å†…å®¹æ•°æ®
    3. ä½¿ç”¨ `/proxy/` æ¥å£ç®¡ç†ä»£ç†è®¾ç½®
    4. æŸ¥çœ‹ `/health` æ£€æŸ¥æœåŠ¡çŠ¶æ€
    """,
    version="1.0.0",
    contact={
        "name": "å†å²æ–‡æœ¬é¡¹ç›®å›¢é˜Ÿ",
        "email": "support@historical-text.com"
    },
    license_info={
        "name": "MIT License",
        "url": "https://opensource.org/licenses/MIT"
    },
    servers=[
        {
            "url": f"http://localhost:{settings.service.port}",
            "description": "å¼€å‘ç¯å¢ƒ"
        },
        {
            "url": "https://api.historical-text.com",
            "description": "ç”Ÿäº§ç¯å¢ƒ"
        }
    ],
    docs_url=settings.service.docs_url,
    redoc_url="/redoc",
    openapi_url=settings.service.openapi_url,
    lifespan=lifespan
)

# é…ç½®CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.service.cors_origins,
    allow_credentials=True,
    allow_methods=settings.service.cors_methods,
    allow_headers=["*"],
)

# é…ç½®ä¿¡ä»»ä¸»æœºä¸­é—´ä»¶ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
if settings.service.environment.value == "production":
    app.add_middleware(
        TrustedHostMiddleware,
        allowed_hosts=["api.historical-text.com", "localhost"]
    )


# å…¨å±€å¼‚å¸¸å¤„ç†å™¨
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """å…¨å±€å¼‚å¸¸å¤„ç†"""
    logger.error(f"å…¨å±€å¼‚å¸¸: {str(exc)}", exc_info=True)
    
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "success": False,
            "error": {
                "code": "INTERNAL_SERVER_ERROR",
                "message": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
                "details": str(exc) if settings.is_development() else None,
                "timestamp": datetime.now().isoformat(),
                "path": str(request.url)
            }
        }
    )


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTPå¼‚å¸¸å¤„ç†"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "success": False,
            "error": {
                "code": f"HTTP_{exc.status_code}",
                "message": exc.detail,
                "timestamp": datetime.now().isoformat(),
                "path": str(request.url)
            }
        }
    )


# è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """è®°å½•è¯·æ±‚æ—¥å¿—"""
    start_time = datetime.now()
    
    # è®°å½•è¯·æ±‚ä¿¡æ¯
    logger.info(f"ğŸ“¥ {request.method} {request.url} - {request.client.host if request.client else 'unknown'}")
    
    # å¤„ç†è¯·æ±‚
    response = await call_next(request)
    
    # è®¡ç®—å¤„ç†æ—¶é—´
    process_time = (datetime.now() - start_time).total_seconds()
    
    # è®°å½•å“åº”ä¿¡æ¯
    logger.info(f"ğŸ“¤ {request.method} {request.url} - {response.status_code} ({process_time:.3f}s)")
    
    # æ·»åŠ å“åº”å¤´
    response.headers["X-Process-Time"] = str(process_time)
    response.headers["X-Service-Name"] = settings.service.service_name
    response.headers["X-Service-Version"] = settings.service.service_version
    
    return response


# æ³¨å†ŒAPIè·¯ç”±
app.include_router(crawler_router, prefix=settings.service.api_prefix)
app.include_router(content_router, prefix=settings.service.api_prefix)
app.include_router(proxy_router, prefix=settings.service.api_prefix)


# æ ¹è·¯å¾„
@app.get("/", tags=["ç³»ç»Ÿ"])
async def root():
    """æœåŠ¡æ ¹è·¯å¾„"""
    return {
        "success": True,
        "data": {
            "service": settings.service.service_name,
            "version": settings.service.service_version,
            "environment": settings.service.environment,
            "status": "running",
            "timestamp": datetime.now().isoformat(),
            "docs_url": settings.service.docs_url,
            "api_prefix": settings.service.api_prefix
        },
        "message": "æ•°æ®æºæœåŠ¡è¿è¡Œä¸­"
    }


# å¥åº·æ£€æŸ¥
@app.get("/health", tags=["ç³»ç»Ÿ"])
async def health_check():
    """æœåŠ¡å¥åº·æ£€æŸ¥"""
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        db_manager = await get_database_manager()
        db_health = await db_manager.health_check()
        
        # æ£€æŸ¥çˆ¬è™«ç®¡ç†å™¨
        crawler_manager = await get_crawler_manager()
        crawler_stats = await crawler_manager.get_statistics()
        
        # æ£€æŸ¥ä»£ç†ç®¡ç†å™¨
        proxy_manager = await get_proxy_manager()
        proxy_stats = proxy_manager.get_proxy_statistics()
        
        # ç»¼åˆå¥åº·çŠ¶æ€
        overall_status = "healthy"
        issues = []
        
        # æ£€æŸ¥æ•°æ®åº“å¥åº·çŠ¶æ€
        if db_health["mongodb"]["status"] != "connected":
            overall_status = "unhealthy"
            issues.append("MongoDBè¿æ¥å¼‚å¸¸")
        
        if db_health["redis"]["status"] != "connected":
            overall_status = "unhealthy"
            issues.append("Redisè¿æ¥å¼‚å¸¸")
        
        # æ£€æŸ¥ä»£ç†çŠ¶æ€
        if proxy_stats["active_proxies"] == 0:
            overall_status = "degraded"
            issues.append("æ²¡æœ‰å¯ç”¨ä»£ç†")
        
        return {
            "success": True,
            "data": {
                "status": overall_status,
                "timestamp": datetime.now().isoformat(),
                "service": {
                    "name": settings.service.service_name,
                    "version": settings.service.service_version,
                    "environment": settings.service.environment
                },
                "components": {
                    "database": db_health,
                    "crawler": {
                        "total_tasks": crawler_stats["total_tasks"],
                        "running_tasks": crawler_stats["running_tasks"],
                        "success_rate": crawler_stats.get("overall_success_rate", 0)
                    },
                    "proxy": {
                        "total_proxies": proxy_stats["total_proxies"],
                        "active_proxies": proxy_stats["active_proxies"],
                        "success_rate": proxy_stats["average_success_rate"]
                    }
                },
                "issues": issues
            },
            "message": f"æœåŠ¡çŠ¶æ€: {overall_status}"
        }
        
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "success": False,
            "data": {
                "status": "unhealthy",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            },
            "message": "å¥åº·æ£€æŸ¥å¤±è´¥"
        }


# æœåŠ¡ä¿¡æ¯
@app.get("/info", tags=["ç³»ç»Ÿ"])
async def service_info():
    """è·å–æœåŠ¡è¯¦ç»†ä¿¡æ¯"""
    return {
        "success": True,
        "data": {
            "service": {
                "name": settings.service.service_name,
                "version": settings.service.service_version,
                "environment": settings.service.environment,
                "host": settings.service.host,
                "port": settings.service.port
            },
            "features": {
                "crawler": {
                    "supported_platforms": ["toutiao", "baijiahao", "xiaohongshu"],
                    "max_concurrent_crawlers": settings.crawler.max_concurrent_crawlers,
                    "proxy_enabled": settings.crawler.enable_proxy
                },
                "content": {
                    "manual_upload": True,
                    "batch_import": True,
                    "file_formats": ["csv", "json"],
                    "search_enabled": True
                },
                "proxy": {
                    "auto_rotation": True,
                    "quality_detection": True,
                    "providers": list(settings.proxy.proxy_providers.keys())
                }
            },
            "api": {
                "prefix": settings.service.api_prefix,
                "docs": settings.service.docs_url,
                "openapi": settings.service.openapi_url
            }
        },
        "message": "æœåŠ¡ä¿¡æ¯è·å–æˆåŠŸ"
    }


# è‡ªå®šä¹‰OpenAPIæ–‡æ¡£
def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
    )
    
    # æ·»åŠ è‡ªå®šä¹‰æ ‡ç­¾
    openapi_schema["tags"] = [
        {
            "name": "ç³»ç»Ÿ",
            "description": "ç³»ç»Ÿçº§æ¥å£ï¼ŒåŒ…æ‹¬å¥åº·æ£€æŸ¥ã€æœåŠ¡ä¿¡æ¯ç­‰"
        },
        {
            "name": "çˆ¬è™«ç®¡ç†", 
            "description": "çˆ¬è™«ä»»åŠ¡çš„åˆ›å»ºã€å¯åŠ¨ã€åœæ­¢å’Œç›‘æ§"
        },
        {
            "name": "å†…å®¹ç®¡ç†",
            "description": "å†…å®¹çš„æ·»åŠ ã€æŸ¥è¯¢ã€æ›´æ–°å’Œåˆ é™¤æ“ä½œ"
        },
        {
            "name": "ä»£ç†ç®¡ç†",
            "description": "ä»£ç†çš„è·å–ã€æµ‹è¯•ã€ç»Ÿè®¡å’Œç®¡ç†"
        }
    ]
    
    app.openapi_schema = openapi_schema
    return app.openapi_schema


app.openapi = custom_openapi


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logger.remove()
    log_format = settings.logging.log_format
    log_level = settings.logging.log_level.value
    
    logger.add(
        sys.stderr,
        format=log_format,
        level=log_level,
        colorize=True
    )
    
    if settings.logging.log_file:
        logger.add(
            settings.logging.log_file,
            format=log_format,
            level=log_level,
            rotation=settings.logging.log_rotation,
            retention=settings.logging.log_retention
        )
    
    # å¯åŠ¨æœåŠ¡
    logger.info("ğŸŒŸ å¯åŠ¨æ•°æ®æºæœåŠ¡...")
    
    uvicorn.run(
        "src.main:app",
        host=settings.service.host,
        port=settings.service.port,
        workers=settings.service.workers,
        reload=settings.is_development(),
        log_config=None,  # ä½¿ç”¨è‡ªå®šä¹‰æ—¥å¿—é…ç½®
        access_log=False   # å…³é—­uvicornè‡ªå¸¦è®¿é—®æ—¥å¿—ï¼Œä½¿ç”¨ä¸­é—´ä»¶è®°å½•
    )