"""
IC-UNIT-001: åˆ†ç±»ç®—æ³•å‡†ç¡®æ€§å•å…ƒæµ‹è¯•
ä¼˜å…ˆçº§: P1 - MLæ ¸å¿ƒé€»è¾‘
"""

import numpy as np
from typing import List, Dict, Tuple, Optional
from sklearn.base import BaseEstimator, ClassifierMixin
import random


class MockMLClassifier(BaseEstimator, ClassifierMixin):
    """æ¨¡æ‹Ÿæœºå™¨å­¦ä¹ åˆ†ç±»å™¨"""
    
    def __init__(self, algorithm: str = "svm", confidence_threshold: float = 0.8):
        self.algorithm = algorithm
        self.confidence_threshold = confidence_threshold
        self.classes_ = None
        self.is_fitted_ = False
        self.feature_names_ = None
        
    def fit(self, X: List[List[float]], y: List[str]) -> 'MockMLClassifier':
        """è®­ç»ƒæ¨¡å‹"""
        self.classes_ = list(set(y))
        self.is_fitted_ = True
        self.feature_names_ = [f"feature_{i}" for i in range(len(X[0]) if X else 0)]
        return self
    
    def predict(self, X: List[List[float]]) -> List[str]:
        """é¢„æµ‹åˆ†ç±»"""
        if not self.is_fitted_:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        predictions = []
        for features in X:
            # æ¨¡æ‹Ÿé¢„æµ‹é€»è¾‘
            if sum(features) > 0.5:
                predictions.append(self.classes_[0] if self.classes_ else "æœªçŸ¥")
            else:
                predictions.append(self.classes_[-1] if self.classes_ else "æœªçŸ¥")
        
        return predictions
    
    def predict_proba(self, X: List[List[float]]) -> List[Dict[str, float]]:
        """é¢„æµ‹æ¦‚ç‡"""
        if not self.is_fitted_:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        probabilities = []
        for features in X:
            # æ¨¡æ‹Ÿæ¦‚ç‡è®¡ç®—
            base_prob = min(max(sum(features), 0.1), 0.9)
            if len(self.classes_) == 2:
                prob_dict = {
                    self.classes_[0]: base_prob,
                    self.classes_[1]: 1.0 - base_prob
                }
            else:
                # å¤šåˆ†ç±»æƒ…å†µ
                remaining_prob = 1.0 - base_prob
                prob_dict = {self.classes_[0]: base_prob}
                for cls in self.classes_[1:]:
                    prob_dict[cls] = remaining_prob / (len(self.classes_) - 1)
            
            probabilities.append(prob_dict)
        
        return probabilities


class TextClassificationService:
    """æ–‡æœ¬åˆ†ç±»æœåŠ¡ - æ¨¡æ‹Ÿå®ç°"""
    
    def __init__(self):
        self.models: Dict[str, MockMLClassifier] = {}
        self.vectorizer = None
        
    def create_model(self, model_name: str, algorithm: str = "svm") -> Dict:
        """åˆ›å»ºåˆ†ç±»æ¨¡å‹"""
        try:
            model = MockMLClassifier(algorithm=algorithm)
            self.models[model_name] = model
            
            return {
                "success": True,
                "model_name": model_name,
                "algorithm": algorithm,
                "status": "created",
                "message": f"æ¨¡å‹ {model_name} åˆ›å»ºæˆåŠŸ"
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ¨¡å‹åˆ›å»ºå¤±è´¥"
            }
    
    def train_model(self, model_name: str, training_data: List[Dict]) -> Dict:
        """è®­ç»ƒåˆ†ç±»æ¨¡å‹"""
        if model_name not in self.models:
            return {"success": False, "error": "æ¨¡å‹ä¸å­˜åœ¨"}
        
        try:
            # æå–ç‰¹å¾å’Œæ ‡ç­¾
            X = []
            y = []
            
            for item in training_data:
                # ç®€å•ç‰¹å¾æå–ï¼šæ–‡æœ¬é•¿åº¦ã€å­—ç¬¦æ•°ç­‰
                text = item.get("text", "")
                features = [
                    len(text) / 1000.0,  # æ–‡æœ¬é•¿åº¦ç‰¹å¾
                    text.count("å†å²") / max(len(text), 1),  # å†å²è¯é¢‘
                    text.count("æ–‡æ¡£") / max(len(text), 1),  # æ–‡æ¡£è¯é¢‘
                    len(text.split()) / max(len(text), 1)   # è¯å¯†åº¦
                ]
                X.append(features)
                y.append(item.get("label", "æœªçŸ¥"))
            
            # è®­ç»ƒæ¨¡å‹
            model = self.models[model_name]
            model.fit(X, y)
            
            # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰
            predictions = model.predict(X)
            accuracy = sum(1 for i in range(len(y)) if predictions[i] == y[i]) / len(y)
            
            return {
                "success": True,
                "model_name": model_name,
                "training_samples": len(training_data),
                "accuracy": accuracy,
                "classes": model.classes_,
                "message": "æ¨¡å‹è®­ç»ƒå®Œæˆ"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ¨¡å‹è®­ç»ƒå¤±è´¥"
            }
    
    def classify_text(self, model_name: str, text: str, return_probabilities: bool = False) -> Dict:
        """åˆ†ç±»å•ä¸ªæ–‡æœ¬"""
        if model_name not in self.models:
            return {"success": False, "error": "æ¨¡å‹ä¸å­˜åœ¨"}
        
        model = self.models[model_name]
        if not model.is_fitted_:
            return {"success": False, "error": "æ¨¡å‹å°šæœªè®­ç»ƒ"}
        
        try:
            # ç‰¹å¾æå–
            features = [
                len(text) / 1000.0,
                text.count("å†å²") / max(len(text), 1),
                text.count("æ–‡æ¡£") / max(len(text), 1),
                len(text.split()) / max(len(text), 1)
            ]
            
            # é¢„æµ‹
            prediction = model.predict([features])[0]
            result = {
                "success": True,
                "text": text,
                "prediction": prediction,
                "model_name": model_name
            }
            
            if return_probabilities:
                probabilities = model.predict_proba([features])[0]
                result["probabilities"] = probabilities
                result["confidence"] = max(probabilities.values())
            
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ–‡æœ¬åˆ†ç±»å¤±è´¥"
            }


class TestMLAlgorithms:
    """æœºå™¨å­¦ä¹ ç®—æ³•æµ‹è¯•å¥—ä»¶"""
    
    def setup_method(self):
        """æµ‹è¯•å‰ç½®è®¾ç½®"""
        self.service = TextClassificationService()
        self.training_data = [
            {"text": "è¿™æ˜¯ä¸€ä»½é‡è¦çš„å†å²æ–‡æ¡£ï¼Œè®°å½•äº†å¤ä»£çš„æ”¿æ²»åˆ¶åº¦", "label": "å†å²"},
            {"text": "æŠ€æœ¯è§„èŒƒæ–‡æ¡£è¯¦ç»†è¯´æ˜äº†ç³»ç»Ÿçš„æ¶æ„è®¾è®¡", "label": "æŠ€æœ¯"},
            {"text": "è´¢åŠ¡æŠ¥å‘Šæ˜¾ç¤ºäº†å…¬å¸çš„ç›ˆåˆ©çŠ¶å†µå’Œå‘å±•è¶‹åŠ¿", "label": "è´¢åŠ¡"},
            {"text": "å¤ä»£æ–‡çŒ®ä¸­è®°è½½äº†ä¸°å¯Œçš„å†å²ä¿¡æ¯å’Œæ–‡åŒ–å†…å®¹", "label": "å†å²"},
            {"text": "è½¯ä»¶å¼€å‘æ–‡æ¡£åŒ…å«äº†è¯¦ç»†çš„APIæ¥å£è¯´æ˜", "label": "æŠ€æœ¯"},
            {"text": "å¹´åº¦è´¢åŠ¡åˆ†ææŠ¥å‘Šå±•ç°äº†ä¼ä¸šçš„ç»è¥æˆæœ", "label": "è´¢åŠ¡"}
        ]
    
    def test_model_creation(self):
        """æµ‹è¯•æ¨¡å‹åˆ›å»º
        
        æµ‹è¯•åœºæ™¯: IC-UNIT-001-001
        éªŒè¯ç‚¹: æ¨¡å‹åˆ›å»ºåŠŸèƒ½å’Œå‚æ•°è®¾ç½®
        """
        # æµ‹è¯•SVMæ¨¡å‹åˆ›å»º
        result = self.service.create_model("test_svm", "svm")
        assert result["success"] is True
        assert result["model_name"] == "test_svm"
        assert result["algorithm"] == "svm"
        
        # æµ‹è¯•RandomForestæ¨¡å‹åˆ›å»º
        result = self.service.create_model("test_rf", "random_forest")
        assert result["success"] is True
        assert result["algorithm"] == "random_forest"
        
        # éªŒè¯æ¨¡å‹å­˜å‚¨
        assert "test_svm" in self.service.models
        assert "test_rf" in self.service.models
        
        print("âœ… IC-UNIT-001-001: æ¨¡å‹åˆ›å»ºæµ‹è¯•é€šè¿‡")
    
    def test_model_training(self):
        """æµ‹è¯•æ¨¡å‹è®­ç»ƒ
        
        æµ‹è¯•åœºæ™¯: IC-UNIT-001-002
        éªŒè¯ç‚¹: æ¨¡å‹è®­ç»ƒè¿‡ç¨‹å’Œç»“æœ
        """
        # åˆ›å»ºæ¨¡å‹
        self.service.create_model("training_test", "svm")
        
        # è®­ç»ƒæ¨¡å‹
        result = self.service.train_model("training_test", self.training_data)
        
        assert result["success"] is True
        assert result["training_samples"] == len(self.training_data)
        assert result["accuracy"] > 0.0  # åº”è¯¥æœ‰ä¸€å®šå‡†ç¡®ç‡
        assert len(result["classes"]) > 0  # åº”è¯¥è¯†åˆ«å‡ºåˆ†ç±»
        
        # éªŒè¯æ¨¡å‹çŠ¶æ€
        model = self.service.models["training_test"]
        assert model.is_fitted_ is True
        assert model.classes_ is not None
        
        print("âœ… IC-UNIT-001-002: æ¨¡å‹è®­ç»ƒæµ‹è¯•é€šè¿‡")
    
    def test_text_classification(self):
        """æµ‹è¯•æ–‡æœ¬åˆ†ç±»
        
        æµ‹è¯•åœºæ™¯: IC-UNIT-001-003
        éªŒè¯ç‚¹: æ–‡æœ¬åˆ†ç±»å‡†ç¡®æ€§
        """
        # å‡†å¤‡è®­ç»ƒå¥½çš„æ¨¡å‹
        self.service.create_model("classification_test", "svm")
        self.service.train_model("classification_test", self.training_data)
        
        # æµ‹è¯•å†å²æ–‡æ¡£åˆ†ç±»
        historical_text = "è¿™æ˜¯ä¸€ä»½å¤ä»£å†å²æ–‡çŒ®ï¼Œæè¿°äº†ç‹æœçš„å…´è¡°å†ç¨‹"
        result = self.service.classify_text("classification_test", historical_text)
        
        assert result["success"] is True
        assert result["prediction"] is not None
        assert result["text"] == historical_text
        
        # æµ‹è¯•æŠ€æœ¯æ–‡æ¡£åˆ†ç±»
        technical_text = "ç³»ç»Ÿæ¶æ„æŠ€æœ¯æ–‡æ¡£è¯´æ˜äº†å¾®æœåŠ¡çš„è®¾è®¡æ¨¡å¼"
        result = self.service.classify_text("classification_test", technical_text)
        
        assert result["success"] is True
        assert result["prediction"] is not None
        
        print("âœ… IC-UNIT-001-003: æ–‡æœ¬åˆ†ç±»æµ‹è¯•é€šè¿‡")
    
    def test_classification_with_probabilities(self):
        """æµ‹è¯•å¸¦æ¦‚ç‡çš„æ–‡æœ¬åˆ†ç±»
        
        æµ‹è¯•åœºæ™¯: IC-UNIT-001-004
        éªŒè¯ç‚¹: åˆ†ç±»ç½®ä¿¡åº¦å’Œæ¦‚ç‡åˆ†å¸ƒ
        """
        # å‡†å¤‡è®­ç»ƒå¥½çš„æ¨¡å‹
        self.service.create_model("prob_test", "svm")
        self.service.train_model("prob_test", self.training_data)
        
        # æµ‹è¯•å¸¦æ¦‚ç‡çš„åˆ†ç±»
        test_text = "å†å²æ–‡æ¡£è®°å½•äº†é‡è¦çš„æ–‡åŒ–é—äº§ä¿¡æ¯"
        result = self.service.classify_text("prob_test", test_text, return_probabilities=True)
        
        assert result["success"] is True
        assert "probabilities" in result
        assert "confidence" in result
        assert isinstance(result["probabilities"], dict)
        assert 0.0 <= result["confidence"] <= 1.0
        
        # éªŒè¯æ¦‚ç‡åˆ†å¸ƒ
        probs = result["probabilities"]
        total_prob = sum(probs.values())
        assert abs(total_prob - 1.0) < 0.01, "æ¦‚ç‡æ€»å’Œåº”è¯¥æ¥è¿‘1.0"
        
        print("âœ… IC-UNIT-001-004: åˆ†ç±»æ¦‚ç‡æµ‹è¯•é€šè¿‡")
    
    def test_model_error_handling(self):
        """æµ‹è¯•æ¨¡å‹é”™è¯¯å¤„ç†
        
        æµ‹è¯•åœºæ™¯: IC-UNIT-001-005
        éªŒè¯ç‚¹: å¼‚å¸¸æƒ…å†µå’Œé”™è¯¯å¤„ç†
        """
        # æµ‹è¯•å¯¹ä¸å­˜åœ¨æ¨¡å‹çš„æ“ä½œ
        result = self.service.classify_text("nonexistent_model", "æµ‹è¯•æ–‡æœ¬")
        assert result["success"] is False
        assert "ä¸å­˜åœ¨" in result["error"]
        
        # æµ‹è¯•å¯¹æœªè®­ç»ƒæ¨¡å‹çš„åˆ†ç±»
        self.service.create_model("untrained_model", "svm")
        result = self.service.classify_text("untrained_model", "æµ‹è¯•æ–‡æœ¬")
        assert result["success"] is False
        assert "å°šæœªè®­ç»ƒ" in result["error"]
        
        # æµ‹è¯•ç©ºè®­ç»ƒæ•°æ®
        result = self.service.train_model("untrained_model", [])
        assert result["success"] is False
        
        print("âœ… IC-UNIT-001-005: æ¨¡å‹é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")
    
    def test_algorithm_performance_comparison(self):
        """æµ‹è¯•ç®—æ³•æ€§èƒ½æ¯”è¾ƒ
        
        æµ‹è¯•åœºæ™¯: IC-UNIT-001-006
        éªŒè¯ç‚¹: ä¸åŒç®—æ³•çš„æ€§èƒ½å¯¹æ¯”
        """
        algorithms = ["svm", "random_forest", "naive_bayes"]
        results = {}
        
        for algorithm in algorithms:
            model_name = f"test_{algorithm}"
            
            # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
            self.service.create_model(model_name, algorithm)
            training_result = self.service.train_model(model_name, self.training_data)
            
            if training_result["success"]:
                results[algorithm] = {
                    "accuracy": training_result["accuracy"],
                    "classes_count": len(training_result["classes"])
                }
        
        # éªŒè¯æ‰€æœ‰ç®—æ³•éƒ½èƒ½æ­£å¸¸å·¥ä½œ
        assert len(results) > 0, "è‡³å°‘åº”è¯¥æœ‰ä¸€ä¸ªç®—æ³•èƒ½æ­£å¸¸å·¥ä½œ"
        
        # éªŒè¯å‡†ç¡®ç‡åœ¨åˆç†èŒƒå›´å†…
        for algorithm, metrics in results.items():
            assert 0.0 <= metrics["accuracy"] <= 1.0, f"{algorithm}çš„å‡†ç¡®ç‡åº”è¯¥åœ¨0-1ä¹‹é—´"
            assert metrics["classes_count"] > 0, f"{algorithm}åº”è¯¥è¯†åˆ«å‡ºåˆ†ç±»"
        
        print("âœ… IC-UNIT-001-006: ç®—æ³•æ€§èƒ½æ¯”è¾ƒæµ‹è¯•é€šè¿‡")
        return results


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    test_ml = TestMLAlgorithms()
    
    print("ğŸ¤– å¼€å§‹æ‰§è¡Œæœºå™¨å­¦ä¹ ç®—æ³•å•å…ƒæµ‹è¯•...")
    test_ml.setup_method()
    test_ml.test_model_creation()
    
    test_ml.setup_method()
    test_ml.test_model_training()
    
    test_ml.setup_method()
    test_ml.test_text_classification()
    
    test_ml.setup_method()
    test_ml.test_classification_with_probabilities()
    
    test_ml.setup_method()
    test_ml.test_model_error_handling()
    
    test_ml.setup_method()
    performance_results = test_ml.test_algorithm_performance_comparison()
    
    print("âœ… æœºå™¨å­¦ä¹ ç®—æ³•å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
    print(f"ğŸ“Š ç®—æ³•æ€§èƒ½å¯¹æ¯”: {performance_results}")