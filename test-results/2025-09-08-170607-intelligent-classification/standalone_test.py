#!/usr/bin/env python3
"""
æ™ºèƒ½åˆ†ç±»æœåŠ¡ç‹¬ç«‹æµ‹è¯•è„šæœ¬
æµ‹è¯•æœåŠ¡çš„åŸºæœ¬åŠŸèƒ½ï¼ˆä¸ä¾èµ–storage-serviceï¼‰
"""

import asyncio
import sys
import os
import json
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ æœåŠ¡æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
script_dir = os.path.dirname(__file__)
service_root = os.path.join(script_dir, '../../services/intelligent-classification-service')
sys.path.insert(0, service_root)
sys.path.insert(0, os.path.join(service_root, 'src'))

class StandaloneTest:
    """ç‹¬ç«‹æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.test_results = {
            "start_time": datetime.now().isoformat(),
            "service": "intelligent-classification-service",
            "test_type": "standalone",
            "tests": [],
            "summary": {
                "total": 0,
                "passed": 0,
                "failed": 0,
                "errors": []
            }
        }
    
    def add_test_result(self, name: str, passed: bool, duration: float, details: dict = None, error: str = None):
        """æ·»åŠ æµ‹è¯•ç»“æœ"""
        self.test_results["tests"].append({
            "name": name,
            "status": "PASSED" if passed else "FAILED",
            "duration": duration,
            "details": details or {},
            "error": error
        })
        
        if passed:
            self.test_results["summary"]["passed"] += 1
        else:
            self.test_results["summary"]["failed"] += 1
            if error:
                self.test_results["summary"]["errors"].append(error)
        
        self.test_results["summary"]["total"] += 1
    
    def test_imports(self):
        """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
        print("ğŸ“¦ æµ‹è¯•æ¨¡å—å¯¼å…¥...")
        start_time = time.time()
        
        try:
            # æµ‹è¯•é…ç½®æ¨¡å—
            from config.settings import settings
            assert settings.service_name == "intelligent-classification-service"
            print(f"  âœ… é…ç½®æ¨¡å—å¯¼å…¥æˆåŠŸ: {settings.service_name}")
            
            # æµ‹è¯•schemaæ¨¡å—
            from schemas.classification_schemas import ClassificationRequest, BaseResponse
            print("  âœ… Schemaæ¨¡å—å¯¼å…¥æˆåŠŸ")
            
            # æµ‹è¯•å·¥å…·æ¨¡å—
            from utils.text_preprocessing import ChineseTextPreprocessor
            from utils.feature_extraction import TfidfFeatureExtractor
            print("  âœ… å·¥å…·æ¨¡å—å¯¼å…¥æˆåŠŸ")
            
            # æµ‹è¯•æœåŠ¡æ¨¡å—
            from services.model_trainer import ModelTrainer
            from services.classification_service import ClassificationService
            print("  âœ… æœåŠ¡æ¨¡å—å¯¼å…¥æˆåŠŸ")
            
            duration = time.time() - start_time
            self.add_test_result("æ¨¡å—å¯¼å…¥æµ‹è¯•", True, duration, {
                "modules_imported": ["config", "schemas", "utils", "services"]
            })
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"æ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.add_test_result("æ¨¡å—å¯¼å…¥æµ‹è¯•", False, duration, error=error_msg)
    
    def test_text_preprocessing(self):
        """æµ‹è¯•æ–‡æœ¬é¢„å¤„ç†åŠŸèƒ½"""
        print("ğŸ”¤ æµ‹è¯•æ–‡æœ¬é¢„å¤„ç†...")
        start_time = time.time()
        
        try:
            from utils.text_preprocessing import ChineseTextPreprocessor, PreprocessingConfig
            
            # åˆ›å»ºé¢„å¤„ç†å™¨
            preprocessor = ChineseTextPreprocessor()
            
            # æµ‹è¯•æ–‡æœ¬
            test_text = "æ¼¢æ­¦å¸æ™‚æœŸï¼Œåœ‹åŠ›å¼·ç››ï¼Œå¤šæ¬¡å‡ºå¾åŒˆå¥´ï¼Œå»ºç«‹äº†å¼·å¤§çš„æ¼¢å¸åœ‹ã€‚"
            
            # é¢„å¤„ç†æµ‹è¯•
            tokens = preprocessor.preprocess(test_text, return_tokens=True)
            processed_text = preprocessor.preprocess(test_text, return_tokens=False)
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = preprocessor.get_text_statistics(test_text)
            
            print(f"  âœ… åŸæ–‡æœ¬: {test_text}")
            print(f"  âœ… å¤„ç†å: {processed_text}")
            print(f"  âœ… åˆ†è¯ç»“æœ: {tokens}")
            print(f"  âœ… ç»Ÿè®¡ä¿¡æ¯: åŸé•¿åº¦={stats['original_length']}, è¯æ•°={stats['token_count']}")
            
            duration = time.time() - start_time
            self.add_test_result("æ–‡æœ¬é¢„å¤„ç†æµ‹è¯•", True, duration, {
                "original_text": test_text,
                "processed_text": processed_text,
                "token_count": len(tokens),
                "statistics": stats
            })
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"æ–‡æœ¬é¢„å¤„ç†å¤±è´¥: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.add_test_result("æ–‡æœ¬é¢„å¤„ç†æµ‹è¯•", False, duration, error=error_msg)
    
    def test_feature_extraction(self):
        """æµ‹è¯•ç‰¹å¾æå–åŠŸèƒ½"""
        print("ğŸ” æµ‹è¯•ç‰¹å¾æå–...")
        start_time = time.time()
        
        try:
            from utils.feature_extraction import TfidfFeatureExtractor
            from utils.text_preprocessing import ChineseTextPreprocessor
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            texts = [
                "æ±‰æ­¦å¸æ—¶æœŸå›½åŠ›å¼ºç››",
                "å”æœè¯—æ­Œè‰ºæœ¯ç¹è£",
                "å®‹æœå•†ä¸šè´¸æ˜“å‘è¾¾",
                "æ˜æœå†›äº‹æŠ€æœ¯å…ˆè¿›"
            ]
            
            # åˆ›å»ºTF-IDFæå–å™¨
            extractor = TfidfFeatureExtractor()
            
            # è®­ç»ƒå’Œæå–ç‰¹å¾
            features = extractor.fit_transform(texts)
            
            print(f"  âœ… è®­ç»ƒæ–‡æœ¬æ•°é‡: {len(texts)}")
            print(f"  âœ… ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {features.shape}")
            print(f"  âœ… è¯æ±‡è¡¨å¤§å°: {len(extractor.get_feature_names())}")
            
            # è·å–é‡è¦è¯æ±‡
            top_words = extractor.get_top_words(10)
            print(f"  âœ… å‰10ä¸ªé‡è¦è¯æ±‡: {[word for word, score in top_words[:5]]}")
            
            duration = time.time() - start_time
            self.add_test_result("ç‰¹å¾æå–æµ‹è¯•", True, duration, {
                "text_count": len(texts),
                "feature_shape": list(features.shape),
                "vocab_size": len(extractor.get_feature_names()),
                "top_words": top_words[:5]
            })
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"ç‰¹å¾æå–å¤±è´¥: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.add_test_result("ç‰¹å¾æå–æµ‹è¯•", False, duration, error=error_msg)
    
    def test_model_trainer_initialization(self):
        """æµ‹è¯•æ¨¡å‹è®­ç»ƒå™¨åˆå§‹åŒ–"""
        print("ğŸ¤– æµ‹è¯•æ¨¡å‹è®­ç»ƒå™¨...")
        start_time = time.time()
        
        try:
            from services.model_trainer import ModelTrainer, TrainingConfig
            from schemas.classification_schemas import ModelType, FeatureExtractorType
            
            # åˆ›å»ºè®­ç»ƒé…ç½®
            config = TrainingConfig(
                test_size=0.3,
                cv_folds=3,
                random_state=42
            )
            
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = ModelTrainer(config)
            
            print(f"  âœ… æ¨¡å‹è®­ç»ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
            print(f"  âœ… é…ç½®æµ‹è¯•é›†å¤§å°: {config.test_size}")
            print(f"  âœ… äº¤å‰éªŒè¯æŠ˜æ•°: {config.cv_folds}")
            
            # æµ‹è¯•æ¨¡å‹æ³¨å†Œè¡¨
            model_types = [ModelType.SVM, ModelType.RANDOM_FOREST]
            for model_type in model_types:
                if model_type in trainer._model_registry:
                    print(f"  âœ… æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
                else:
                    print(f"  âš ï¸  æ¨¡å‹ç±»å‹æœªæ³¨å†Œ: {model_type}")
            
            duration = time.time() - start_time
            self.add_test_result("æ¨¡å‹è®­ç»ƒå™¨æµ‹è¯•", True, duration, {
                "trainer_initialized": True,
                "test_size": config.test_size,
                "cv_folds": config.cv_folds,
                "supported_models": len(trainer._model_registry)
            })
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"æ¨¡å‹è®­ç»ƒå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.add_test_result("æ¨¡å‹è®­ç»ƒå™¨æµ‹è¯•", False, duration, error=error_msg)
    
    def test_classification_schemas(self):
        """æµ‹è¯•åˆ†ç±»æ•°æ®æ¨¡å‹"""
        print("ğŸ“‹ æµ‹è¯•æ•°æ®æ¨¡å‹...")
        start_time = time.time()
        
        try:
            from schemas.classification_schemas import (
                ClassificationRequest, 
                BaseResponse,
                TrainingDataCreate,
                ModelTrainingRequest,
                ClassificationType
            )
            
            # æµ‹è¯•åˆ†ç±»è¯·æ±‚æ¨¡å‹
            request_data = {
                "project_id": "test-project-123",
                "text_content": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬",
                "return_probabilities": True,
                "return_explanation": True
            }
            
            request = ClassificationRequest(**request_data)
            print(f"  âœ… åˆ†ç±»è¯·æ±‚æ¨¡å‹åˆ›å»ºæˆåŠŸ: {request.project_id}")
            
            # æµ‹è¯•åŸºç¡€å“åº”æ¨¡å‹
            response_data = {
                "success": True,
                "message": "æµ‹è¯•æˆåŠŸ",
                "data": {"result": "test"}
            }
            
            response = BaseResponse(**response_data)
            print(f"  âœ… åŸºç¡€å“åº”æ¨¡å‹åˆ›å»ºæˆåŠŸ: {response.message}")
            
            # æµ‹è¯•è®­ç»ƒæ•°æ®æ¨¡å‹
            training_data = {
                "project_id": "test-project-123",
                "text_content": "è®­ç»ƒæ–‡æœ¬ç¤ºä¾‹",
                "true_label": "æ”¿æ²»",
                "label_confidence": 1.0,
                "data_source": "test"
            }
            
            training_request = TrainingDataCreate(**training_data)
            print(f"  âœ… è®­ç»ƒæ•°æ®æ¨¡å‹åˆ›å»ºæˆåŠŸ: {training_request.true_label}")
            
            # æµ‹è¯•åˆ†ç±»ç±»å‹æšä¸¾
            classification_types = [t.value for t in ClassificationType]
            print(f"  âœ… æ”¯æŒçš„åˆ†ç±»ç±»å‹: {classification_types}")
            
            duration = time.time() - start_time
            self.add_test_result("æ•°æ®æ¨¡å‹æµ‹è¯•", True, duration, {
                "models_tested": ["ClassificationRequest", "BaseResponse", "TrainingDataCreate"],
                "classification_types": classification_types
            })
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"æ•°æ®æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.add_test_result("æ•°æ®æ¨¡å‹æµ‹è¯•", False, duration, error=error_msg)
    
    def test_configuration(self):
        """æµ‹è¯•é…ç½®ç³»ç»Ÿ"""
        print("âš™ï¸ æµ‹è¯•é…ç½®ç³»ç»Ÿ...")
        start_time = time.time()
        
        try:
            from config.settings import settings
            
            # æµ‹è¯•åŸºæœ¬é…ç½®
            assert settings.service_name == "intelligent-classification-service"
            assert settings.api_port == 8007
            
            print(f"  âœ… æœåŠ¡åç§°: {settings.service_name}")
            print(f"  âœ… æœåŠ¡ç«¯å£: {settings.api_port}")
            print(f"  âœ… ç¯å¢ƒ: {settings.environment}")
            
            # æµ‹è¯•é¢„å®šä¹‰æ ‡ç­¾
            topic_labels = settings.get_classification_labels("topic")
            print(f"  âœ… ä¸»é¢˜åˆ†ç±»æ ‡ç­¾æ•°é‡: {len(topic_labels)}")
            print(f"  âœ… ä¸»é¢˜æ ‡ç­¾ç¤ºä¾‹: {topic_labels[:3]}")
            
            # æµ‹è¯•æ¨¡å‹é…ç½®
            rf_config = settings.get_model_config("random_forest")
            print(f"  âœ… éšæœºæ£®æ—é…ç½®: n_estimators={rf_config.get('n_estimators')}")
            
            # æµ‹è¯•ç‰¹å¾é…ç½®
            tfidf_config = settings.get_feature_config("tfidf")
            print(f"  âœ… TF-IDFé…ç½®: max_features={tfidf_config.get('max_features')}")
            
            duration = time.time() - start_time
            self.add_test_result("é…ç½®ç³»ç»Ÿæµ‹è¯•", True, duration, {
                "service_name": settings.service_name,
                "api_port": settings.api_port,
                "topic_labels_count": len(topic_labels),
                "has_model_config": bool(rf_config),
                "has_feature_config": bool(tfidf_config)
            })
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"é…ç½®ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.add_test_result("é…ç½®ç³»ç»Ÿæµ‹è¯•", False, duration, error=error_msg)
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†ç±»æœåŠ¡ç‹¬ç«‹æµ‹è¯•...")
        print("=" * 60)
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        self.test_imports()
        self.test_configuration()
        self.test_classification_schemas()
        self.test_text_preprocessing()
        self.test_feature_extraction()
        self.test_model_trainer_initialization()
        
        # å®Œæˆæµ‹è¯•
        self.test_results["end_time"] = datetime.now().isoformat()
        self.test_results["total_duration"] = sum(
            test.get("duration", 0) for test in self.test_results["tests"]
        )
        
        # è®¡ç®—æˆåŠŸç‡
        passed = self.test_results["summary"]["passed"]
        total = self.test_results["summary"]["total"]
        self.test_results["summary"]["success_rate"] = (passed / total * 100) if total > 0 else 0
        
        return self.test_results

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª æ™ºèƒ½åˆ†ç±»æœåŠ¡ç‹¬ç«‹åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print("ğŸ“ è¯´æ˜: æ­¤æµ‹è¯•ä¸ä¾èµ–å¤–éƒ¨æœåŠ¡ï¼Œä»…æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½æ¨¡å—")
    print()
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = StandaloneTest()
    
    # è¿è¡Œæµ‹è¯•
    results = await tester.run_all_tests()
    
    # æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"ğŸ¯ æ€»æµ‹è¯•æ•°: {results['summary']['total']}")
    print(f"âœ… é€šè¿‡: {results['summary']['passed']}")
    print(f"âŒ å¤±è´¥: {results['summary']['failed']}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {results['summary']['success_rate']:.1f}%")
    print(f"â±ï¸  æ€»è€—æ—¶: {results['total_duration']:.2f}ç§’")
    
    if results['summary']['errors']:
        print(f"\nâ— é”™è¯¯åˆ—è¡¨:")
        for i, error in enumerate(results['summary']['errors'], 1):
            print(f"  {i}. {error}")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    result_file = "standalone_test_results.json"
    with open(result_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    print("ğŸ ç‹¬ç«‹æµ‹è¯•å®Œæˆ")
    
    return results

if __name__ == "__main__":
    # åˆ‡æ¢åˆ°æ™ºèƒ½åˆ†ç±»æœåŠ¡ç›®å½•
    script_dir = Path(__file__).parent
    service_dir = script_dir.parent.parent / "services" / "intelligent-classification-service"
    
    if service_dir.exists():
        os.chdir(service_dir)
        print(f"ğŸ“ åˆ‡æ¢åˆ°æœåŠ¡ç›®å½•: {service_dir}")
    else:
        # å¦‚æœåœ¨æ™ºèƒ½åˆ†ç±»æœåŠ¡ç›®å½•ä¸­
        if Path("src").exists() and Path("requirements.txt").exists():
            print(f"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}")
        else:
            print("âŒ æ— æ³•æ‰¾åˆ°æ™ºèƒ½åˆ†ç±»æœåŠ¡ç›®å½•")
            sys.exit(1)
    
    asyncio.run(main())